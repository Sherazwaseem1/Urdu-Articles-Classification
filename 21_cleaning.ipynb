{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.0 MB 2.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 2.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.1/10.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.2/10.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 6.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "Successfully installed safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Talha\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openpyxl in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (3.1.5)\n",
      "Requirement already satisfied: urduhack in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (1.0.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: tensorflow-datasets~=3.1 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from urduhack) (3.2.1)\n",
      "Requirement already satisfied: Click~=7.1 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from urduhack) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from urduhack) (2024.9.11)\n",
      "Requirement already satisfied: absl-py in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.1.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (24.2.0)\n",
      "Requirement already satisfied: dill in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (0.3.8)\n",
      "Requirement already satisfied: future in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.0.2)\n",
      "Requirement already satisfied: promise in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (5.28.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.16.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (2.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (4.66.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-datasets~=3.1->urduhack) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (2024.8.30)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-metadata->tensorflow-datasets~=3.1->urduhack) (1.66.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\talha\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->tensorflow-datasets~=3.1->urduhack) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Install dependencies\n",
    "!pip3 install openpyxl urduhack\n",
    "\n",
    "from urduhack.normalization import normalize\n",
    "from urduhack.stop_words import STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to cleaned_news_articles.csv\n",
      "Tokenized data saved to tokenized_news_articles.csv\n",
      "                                             content  \\\n",
      "0  لاہور دوستی انٹرنیشنل تھیٹر فیسٹیول آغاز ، شان...   \n",
      "1  بالی ووڈ دبنگ خان ممبئی موجود شاہ رخ خان پرتعی...   \n",
      "2  شہرت بلندیوں چھونے بالی ووڈ اداکار پربھاس بڑا ...   \n",
      "3  آرٹس کونسل آف پاکستان کراچی زیر اہتمام 21 روزہ...   \n",
      "4  پاکستان شوبز اداکار ہدایتکار یاسر نواز سوشل می...   \n",
      "\n",
      "                                   tokenized_content  token_length  \n",
      "0  [6891, 3671, 5845, 10261, 16898, 749, 105, 83,...           248  \n",
      "1  [15745, 12008, 26196, 700, 4365, 562, 906, 232...           146  \n",
      "2  [37833, 14900, 15949, 7231, 12008, 6436, 34512...           169  \n",
      "3  [76499, 3520, 1123, 415, 1141, 1108, 4919, 211...           512  \n",
      "4  [1757, 36909, 6436, 23172, 7380, 1477, 5701, 1...           133  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "file_path = 'news_article_combined.xlsx'  \n",
    "try:\n",
    "    data = pd.read_excel(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {file_path} not found.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Data cleaning\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna(subset=['title', 'content', 'gold_label'])\n",
    "data['gold_label'] = data['gold_label'].replace({'science-technology-technology': 'science-technology'})\n",
    "\n",
    "def clean_text(text):\n",
    "    text = normalize(text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in STOP_WORDS]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "data['content'] = data['content'].apply(clean_text).apply(remove_stopwords)\n",
    "data['title'] = data['title'].apply(clean_text).apply(remove_stopwords)\n",
    "\n",
    "# Save cleaned data\n",
    "cleaned_file_path = 'cleaned_news_articles.csv'\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"hadidev/gpt2-urdu-tokenizer-withgpt2\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading tokenizer: {e}\")\n",
    "    exit()\n",
    "\n",
    "data['tokenized_content'] = data['content'].apply(\n",
    "    lambda x: tokenizer.encode(x, truncation=True, max_length=512)\n",
    ")\n",
    "data['token_length'] = data['tokenized_content'].apply(len)\n",
    "\n",
    "tokenized_file_path = 'tokenized_news_articles.csv'\n",
    "data.to_csv(tokenized_file_path, index=False)\n",
    "print(f\"Tokenized data saved to {tokenized_file_path}\")\n",
    "\n",
    "print(data[['content', 'tokenized_content', 'token_length']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
